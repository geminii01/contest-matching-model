{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain import hub\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith Project: matching_model_demo\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "UPSTAGE_API_KEY = os.environ.get('UPSTAGE_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.environ.get('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'matching_model_demo' # 프로젝트명 수정\n",
    "LANGCHAIN_PROJECT = os.environ.get('LANGCHAIN_PROJECT')\n",
    "\n",
    "print(f'LangSmith Project: {LANGCHAIN_PROJECT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 구성\n",
    "\n",
    "> 전처리, csv to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 데이터 로드 완료\n",
      "> 데이터 전처리 완료\n",
      "> 데이터 결측치 확인\n",
      "-------------------------\n",
      "ID      0\n",
      "CODE    0\n",
      "DSC     0\n",
      "dtype: int64\n",
      "ISIC4_CODE     0\n",
      "ISIC4_NAME     0\n",
      "KSIC10_CODE    0\n",
      "KSIC10_NAME    0\n",
      "HS2017_CODE    0\n",
      "HS2017_NAME    0\n",
      "dtype: int64\n",
      "HS_CODE     0\n",
      "KOR_NAME    0\n",
      "ENG_NAME    0\n",
      "INT_CODE    0\n",
      "INT_NAME    0\n",
      "dtype: int64\n",
      "-------------------------\n",
      "> csv to jsonl 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "text = pd.read_excel('../data/비식별된 해외기업별 영문 텍스트데이터.xlsx')\n",
    "statis = pd.read_excel('../data/통계청 국제표준산업분류 HSCODE 6단위 매핑.xlsx')\n",
    "customs = pd.read_excel('../data/관세청_HS부호_240101.xlsx')\n",
    "\n",
    "text_copy = text.copy()\n",
    "statis_copy = statis.copy()\n",
    "customs_copy = customs.copy()\n",
    "\n",
    "print('> 데이터 로드 완료')\n",
    "\n",
    "\n",
    "# 데이터 전처리\n",
    "\n",
    "def zero_input(num, x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        cnt = num - len(x)\n",
    "        return '0' * cnt + x\n",
    "    \n",
    "def re_sub(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return re.sub(r'^\\((.*?)\\)$', r'\\1', x)\n",
    "\n",
    "text_copy['ID'] = text_copy['ID'].astype(str)\n",
    "text_copy['CODE'] = text_copy['CODE'].astype(str)\n",
    "text_copy['CODE'] = text_copy['CODE'].apply(lambda x: zero_input(4, x))\n",
    "\n",
    "statis_copy.columns = [\n",
    "    'ISIC4_CODE', # ISIC4_국제표준산업분류\n",
    "    'ISIC4_NAME', # ISIC4_분류명\n",
    "    'KSIC10_CODE', # KSIC10_한국표준산업분류\n",
    "    'KSIC10_NAME', # KSIC10_분류명\n",
    "    'HS2017_CODE', # HS2017_관세통계통합품목분류\n",
    "    'HS2017_NAME' # HS2017_분류명\n",
    "]\n",
    "\n",
    "statis_copy['ISIC4_CODE'] = statis_copy['ISIC4_CODE'].astype(str)\n",
    "statis_copy['ISIC4_CODE'] = statis_copy['ISIC4_CODE'].replace('nan', np.nan)\n",
    "statis_copy['ISIC4_CODE'] = statis_copy['ISIC4_CODE'].str.replace('.0', '', regex=False)\n",
    "statis_copy['ISIC4_CODE'] = statis_copy['ISIC4_CODE'].apply(lambda x: zero_input(4, x))\n",
    "\n",
    "statis_copy['HS2017_CODE'] = statis_copy['HS2017_CODE'].astype(str)\n",
    "statis_copy['HS2017_CODE'] = statis_copy['HS2017_CODE'].replace('nan', np.nan)\n",
    "statis_copy['HS2017_CODE'] = statis_copy['HS2017_CODE'].str.replace('.0', '', regex=False)\n",
    "statis_copy['HS2017_CODE'] = statis_copy['HS2017_CODE'].apply(lambda x: zero_input(6, x))\n",
    "\n",
    "customs_copy.columns = [\n",
    "    'HS_CODE', # HS부호\n",
    "    'KOR_NAME', # 한글품목명\n",
    "    'ENG_NAME', # 영문품목명\n",
    "    'INT_CODE', # 성질통합분류코드\n",
    "    'INT_NAME' # 성질통합분류명\n",
    "]\n",
    "\n",
    "customs_copy['HS_CODE'] = customs_copy['HS_CODE'].astype(str)\n",
    "customs_copy['HS_CODE'] = customs_copy['HS_CODE'].apply(lambda x: zero_input(10, x))\n",
    "\n",
    "customs_copy['INT_CODE'] = customs_copy['INT_CODE'].astype(str)\n",
    "customs_copy['INT_CODE'] = customs_copy['INT_CODE'].replace('nan', np.nan)\n",
    "customs_copy['INT_CODE'] = customs_copy['INT_CODE'].str.replace('.0', '', regex=False)\n",
    "\n",
    "customs_copy['INT_NAME'] = customs_copy['INT_NAME'].apply(lambda x: re_sub(x))\n",
    "\n",
    "text_copy = text_copy.fillna(' ')\n",
    "statis_copy = statis_copy.fillna(' ')\n",
    "customs_copy = customs_copy.fillna(' ')\n",
    "\n",
    "print('> 데이터 전처리 완료')\n",
    "print('> 데이터 결측치 확인')\n",
    "print('-----' * 5)\n",
    "print(text_copy.isnull().sum())\n",
    "print(statis_copy.isnull().sum())\n",
    "print(customs_copy.isnull().sum())\n",
    "print('-----' * 5)\n",
    "\n",
    "\n",
    "# 데이터 저장 및 로드\n",
    "\n",
    "text_copy.to_csv('../data/prepro_text.csv', index=False, encoding='utf-8')\n",
    "statis_copy.to_csv('../data/prepro_statis.csv', index=False, encoding='utf-8')\n",
    "customs_copy.to_csv('../data/prepro_customs.csv', index=False, encoding='utf-8')\n",
    "\n",
    "text_prepro = pd.read_csv('../data/prepro_text.csv', dtype=str)\n",
    "statis_prepro = pd.read_csv('../data/prepro_statis.csv', dtype=str)\n",
    "customs_prepro = pd.read_csv('../data/prepro_customs.csv', dtype=str)\n",
    "\n",
    "\n",
    "# csv to jsonl\n",
    "\n",
    "def csv_to_jsonl(csv_file_path, jsonl_file_path):\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        with open(jsonl_file_path, mode='w', encoding='utf-8') as jsonl_file:\n",
    "            for row in csv_reader:\n",
    "                jsonl_file.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
    "\n",
    "csv_to_jsonl('../data/prepro_text.csv', '../data/jsonl_prepro_text.jsonl')\n",
    "csv_to_jsonl('../data/prepro_statis.csv', '../data/jsonl_prepro_statis.jsonl')\n",
    "csv_to_jsonl('../data/prepro_customs.csv', '../data/jsonl_prepro_customs.jsonl')\n",
    "print('> csv to jsonl 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document 구성\n",
    "\n",
    "> 통계청, 관세청에서 텍스트 스플릿 따로 안 함. 길이가 짧음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automotive repair shops, nec  specialized automotive repair, not elsewhere classified, such as fuel service carburetor repair, brake relining, front-end and wheel alignment, and radiator repair. motor vehicle repair and maintenance auto brake lining, installation other automotive mechanical and electrical repair and maintenance maintenance and repair of motor vehicles maintenance and repair of motor vehicles maintenance and repair of motor vehiclesother automotive repair and maintenance\n",
      "{'CODE': '4520',\n",
      " 'ID': '1',\n",
      " 'seq_num': 1,\n",
      " 'source': '/root/contest-matching-model/data/jsonl_prepro_text.jsonl'}\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/jsonl_prepro_text.jsonl'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.',\n",
    "    text_content=False,\n",
    "    json_lines=True,\n",
    ")\n",
    "temp = loader.load()\n",
    "\n",
    "seq_num = 1\n",
    "text_documents = []\n",
    "for tmp in temp:\n",
    "    data = json.loads(tmp.page_content)\n",
    "    doc = Document(\n",
    "        page_content=data['DSC'], \n",
    "        metadata={\n",
    "            'ID': data['ID'],\n",
    "            'CODE': data['CODE'],\n",
    "            'source': '/root/contest-matching-model/data/jsonl_prepro_text.jsonl',\n",
    "            'seq_num': seq_num,\n",
    "        }\n",
    "    )\n",
    "    text_documents.append(doc)\n",
    "    seq_num += 1\n",
    "\n",
    "print(text_documents[0].page_content)\n",
    "pprint(text_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "곡물(쌀 제외), 콩류, 종실유 재배업\n",
      "종자 및 묘목 생산업\n",
      "종자\n",
      "{'HS2017_CODE': '100111',\n",
      " 'ISIC4_CODE': '0111',\n",
      " 'KSIC10_CODE': '01123',\n",
      " 'seq_num': 1,\n",
      " 'source': '/root/contest-matching-model/data/jsonl_prepro_statis.jsonl'}\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/jsonl_prepro_statis.jsonl'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.',\n",
    "    text_content=False,\n",
    "    json_lines=True,\n",
    ")\n",
    "temp = loader.load()\n",
    "\n",
    "seq_num = 1\n",
    "statis_documents = []\n",
    "for tmp in temp:\n",
    "    data = json.loads(tmp.page_content)\n",
    "    doc = Document(\n",
    "        page_content=f\"{data['ISIC4_NAME']}\\r\\n{data['KSIC10_NAME']}\\r\\n{data['HS2017_NAME']}\", # ISIC4, KSIC10, HS2017 순으로 작성됨\n",
    "        metadata={\n",
    "            'ISIC4_CODE': data['ISIC4_CODE'],\n",
    "            'KSIC10_CODE': data['KSIC10_CODE'],\n",
    "            'HS2017_CODE': data['HS2017_CODE'],\n",
    "            'source': '/root/contest-matching-model/data/jsonl_prepro_statis.jsonl',\n",
    "            'seq_num': seq_num,\n",
    "        }\n",
    "    )\n",
    "    statis_documents.append(doc)\n",
    "    seq_num += 1\n",
    "\n",
    "print(statis_documents[0].page_content)\n",
    "pprint(statis_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## customs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "농가 사육용\n",
      "For farm breeding\n",
      "말\n",
      "{'HS_CODE': '0101211000',\n",
      " 'INT_CODE': '11020101',\n",
      " 'seq_num': 1,\n",
      " 'source': '/root/contest-matching-model/data/jsonl_prepro_customs.jsonl'}\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/jsonl_prepro_customs.jsonl'\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.',\n",
    "    text_content=False,\n",
    "    json_lines=True,\n",
    ")\n",
    "temp = loader.load()\n",
    "\n",
    "seq_num = 1\n",
    "customs_documents = []\n",
    "for tmp in temp:\n",
    "    data = json.loads(tmp.page_content)\n",
    "    doc = Document(\n",
    "        page_content=f\"{data['KOR_NAME']}\\r\\n{data['ENG_NAME']}\\r\\n{data['INT_NAME']}\", # 한글품목명, 영어품목명, 성질 통합 분류명 순으로 작성됨\n",
    "        metadata={\n",
    "            'HS_CODE': data['HS_CODE'],\n",
    "            'INT_CODE': data['INT_CODE'],\n",
    "            'source': '/root/contest-matching-model/data/jsonl_prepro_customs.jsonl',\n",
    "            'seq_num': seq_num,\n",
    "        }\n",
    "    )\n",
    "    customs_documents.append(doc)\n",
    "    seq_num += 1\n",
    "\n",
    "print(customs_documents[0].page_content)\n",
    "pprint(customs_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터스토어 생성\n",
    "\n",
    "> 통계청, 관세청만 해당함 (텍스트는 인풋 값이어서 벡터스토어에 안 넣음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "embeddings = UpstageEmbeddings(\n",
    "    api_key=UPSTAGE_API_KEY, \n",
    "    model=\"solar-embedding-1-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'statis'\n",
    "folder_path = f'./faiss_{name}'\n",
    "if not os.path.exists(folder_path):\n",
    "    print(f'> {name} Vector Store 생성 중')\n",
    "    statis_vectorstore = FAISS.from_documents(\n",
    "        documents=statis_documents,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "    statis_vectorstore.save_local(folder_path=folder_path)\n",
    "    print(f'> {name} Vector Store 생성 및 로컬 저장 완료')\n",
    "else:\n",
    "    statis_vectorstore = FAISS.load_local(\n",
    "        folder_path=folder_path, \n",
    "        embeddings=embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f'> {name} Vector Store 로컬에서 불러옴')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## customs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'customs'\n",
    "folder_path = f'./faiss_{name}'\n",
    "if not os.path.exists(folder_path):\n",
    "    print(f'> {name} Vector Store 생성 중')\n",
    "    customs_vectorstore = FAISS.from_documents(\n",
    "        documents=customs_documents,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "    customs_vectorstore.save_local(folder_path=folder_path)\n",
    "    print(f'> {name} Vector Store 생성 및 로컬 저장 완료')\n",
    "else:\n",
    "    customs_vectorstore = FAISS.load_local(\n",
    "        folder_path=folder_path, \n",
    "        embeddings=embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f'> {name} Vector Store 로컬에서 불러옴')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 적절한 HS CODE 찾는 프로세스\n",
    "\n",
    "> 텍스트의 jsonl 한 줄 들어옴\n",
    "\n",
    "> 텍스트의 ISIC4와 통계청의 ISIC4 같은거 찾기 (metadata 끼리 비교)<br>유사도 검색 수행도 해서 비교하기\n",
    "\n",
    "> 조건 거친 통계청의 page_content를 텍스트의 page_content와 비교하여 적절한 통계청 찾기 (점수 기반 유사도 또는 retriever)\n",
    "\n",
    "> 조건 거친 통계청의 page_content와(단일 또는 복수) 텍스트의 page_content를 컨텍스트로 주고, 관세청의 page_content와 비교\n",
    "\n",
    "> 관세청 HS_CODE topk(k >= 10) 추출\n",
    "\n",
    "> 위 과정에서 레퍼런스 잘 챙기기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트의 ISIC4와 통계청의 ISIC4 같은거 찾기 (metadata 끼리 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore에서 유사도 검색\n",
    "query = text_documents[0].page_content\n",
    "print(query)\n",
    "\n",
    "statis_similarity = statis_vectorstore.similarity_search(\n",
    "    query=query,\n",
    "    k=10\n",
    ")\n",
    "i = 1\n",
    "for doc in statis_similarity:\n",
    "    print(f'\\n{i}.')\n",
    "    print(doc.page_content)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore에서 점수에 기반한 유사도 검색\n",
    "query = text_documents[0].page_content\n",
    "print(query)\n",
    "\n",
    "statis_score = statis_vectorstore.similarity_search_with_score(\n",
    "    query=query,\n",
    "    k=10\n",
    ")\n",
    "i = 1\n",
    "for doc in statis_score:\n",
    "    content, score = doc\n",
    "    print(f'\\n{i}.')\n",
    "    print(content.page_content)\n",
    "    print(score)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
